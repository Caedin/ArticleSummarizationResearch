Author: Keith Dyer

This folder contains the work I did to try to come up with new summarization techniques. It includes code written to generate summaries, as well as code written to 
evaluate and compare the different methods. 

Directories:
	BON = Bit of News. This is an open source summarizer algorithm used by a reddit summery bot. The folder contains the generated summaries for the DUC data set.
	DUC = Document Understanding Conference data sets. The data set used for generating the summaries is from 2002 by default but can be changed in Batch_Summarizer.py
	MOD = Modified text rank algorithm. This folder contains summaries generated by my modified text rank algorithm.
	OPT = Set of optimally selected sentences from the DUC 2002 data. This represents an upper bound on what the algorithmic summarizers can achieve.
	Tests = Recorded tests of different summarizers.
	TRS = Text Rank System. This contains the summaries of the standard text rank algorithm (re-written based on the specifications in their paper).

Files:
	Batch_Summarizer.py = This python code generates extracted summaries for BON, MOD, and TRS. The algorithm/s can be specified as command line options. The data set can be changed by changing the path variable.
	BitOfNews.py = This code calls the open source library BitOfNews to automatically generate a summary from an input article.
	Modified_TextRank.py = This code generates an extracted summary using my modified text rank algorithm, the article is accepted as an input.
	TextRank.py = This code generates an extracted summary using the original text rank algorithm as rewritten by me as close to the paper's specification as possible. The article is accepted as input.
	Evaluator.py = This code evaluates the extracted summaries generated after calling Batch_Summarizer. It generates the average word overlap with the gold standard, and calculates a paired t-test for significance. I've put previous outputs in the TESTS folder.

Other:
	Machine Learning. This folder contains the contents of my machine learning approaches. I used 4 data sets containing the occurrences of Parts of Speech. I used  
	one through four grams for parts of speech, and attempted to classify summary and non-summary sentences using a variety of ML algorithms. The data sets are in the Machine
	Learning Folder in ARFF form. The code to extract the N-grams is Feature_Extractor.py, and the results are in Results.

How I used this system:
	These code files allowed me to rapidly test different strategies for summaries. I was able to change Modified_TextRank.py to include a new idea, (such as say a new similarity function for the graph)
	and then I can call Batch_Summarizer.py and Evaluator.py to get results of the new algorithm/idea in a very short time.
	

Background Research:
	I based my work on the following publications:
		TextRank: Bringing Order into Texts. Rada Mihalcea and Paul Tarau. University of North Texas.
			This paper founded the basis for my research. I implemented their text rank code for summarization and for key word extraction in Python. I modified their
			methods and compared the performance of those modified methods on the DUC data set.
		A Survey of Text Summarization Extractive Techniques. Vishal Gupta, University Institute of Engineering & Technology, Panjab University Chandigarh, India and Gurpeet Singh Lehal Punjabi University Patiala, Punjab, India.
			This paper provided a background and survey of popular extractive summarization techniques using in NLP, and provided a context for understanding the problem and the approaches already tried to solve the problem.
		Combining Syntax and Semantics for Automatic Extractive Single-Document Summarization. Araly Barrera and Rakesh Verma. University of Houston, Houston TX, USA.
			This paper covers and compares summarization techniques using an ensemble scoring system combining TextRank, Position, and WordNet scores. They demonstrate that they get improved
			performance by including the semantic data from WordNet, and the positional data. My work could be further improved by incorporating positional data and semantic data, but I ran out of time.
			
Complications Encountered:
	I was wanting to use the ROUGE program to evaluate my summaries, but unfortunately I wasn't able to get it working. I acquired the software from the creator but had Perl dependency issues on both Windows and Ubuntu.
	I am unfamiliar with Perl and I wasn't able to resolve the dependencies issues, so I only have results from my own analysis.
	
	
	
